<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <meta charset="utf-8">
<title>DeBERTa è®ºæ–‡è§£è¯» - Fan&#39;s Blog</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">




<meta name="description" content="ğŸ¤£åºŸå®…ï½œç©·ğŸ¤©ï½œæƒ³å˜èƒ–ğŸ’ª">





    <meta name="description" content="ã€ŠDeberta: decoding-Enhanced Bert with Disentangled Attentionã€‹ï¼Œè¯¥è®ºæ–‡æ¥è‡ª ICLR2021ï¼Œä½œè€…å›¢é˜Ÿä¸ºå¾®è½¯ï¼Œä¸»è¦ä»‹ç»äº†å…¶æå‡ºçš„ä¸€ä¸ªæ–°çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼šDeBERTaï¼Œè¯¥æ¨¡å‹ä»æ³¨æ„åŠ›è§£è€¦ï¼ˆdisentangled attentionï¼‰å’Œé¢„è®­ç»ƒé˜¶æ®µçš„è§£ç å¢å¼ºä¸¤æ–¹é¢å¯¹BERTç±»é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¹¶åœ¨SuperGLUEä¸Šé¦–æ¬¡è¶…è¶Šäººç±»åŸºå‡†ã€‚">
<meta property="og:type" content="article">
<meta property="og:title" content="DeBERTa è®ºæ–‡è§£è¯»">
<meta property="og:url" content="https://aestheticisma.github.io/2021/11/24/deberta/index.html">
<meta property="og:site_name" content="Fan&#39;s Blog">
<meta property="og:description" content="ã€ŠDeberta: decoding-Enhanced Bert with Disentangled Attentionã€‹ï¼Œè¯¥è®ºæ–‡æ¥è‡ª ICLR2021ï¼Œä½œè€…å›¢é˜Ÿä¸ºå¾®è½¯ï¼Œä¸»è¦ä»‹ç»äº†å…¶æå‡ºçš„ä¸€ä¸ªæ–°çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼šDeBERTaï¼Œè¯¥æ¨¡å‹ä»æ³¨æ„åŠ›è§£è€¦ï¼ˆdisentangled attentionï¼‰å’Œé¢„è®­ç»ƒé˜¶æ®µçš„è§£ç å¢å¼ºä¸¤æ–¹é¢å¯¹BERTç±»é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¹¶åœ¨SuperGLUEä¸Šé¦–æ¬¡è¶…è¶Šäººç±»åŸºå‡†ã€‚">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://aestheticisma.github.io/2021/11/24/deberta/bert_input.png">
<meta property="og:image" content="https://aestheticisma.github.io/2021/11/24/deberta/decoder_layer.png">
<meta property="og:image" content="https://aestheticisma.github.io/2021/11/24/deberta/SiFT_results.png">
<meta property="article:published_time" content="2021-11-24T10:21:44.000Z">
<meta property="article:modified_time" content="2021-11-24T10:21:28.122Z">
<meta property="article:author" content="æµå²š">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://aestheticisma.github.io/2021/11/24/deberta/bert_input.png">





<link rel="icon" href="/favicon-32x32.ico">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">


<link rel="stylesheet" href="/css/style.css">


<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    
    
    
    
    
    
    
    
    

    


<meta name="generator" content="Hexo 6.0.0"></head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                    
                    æµå²š
                    
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/archives">Archives</a>
            
            <a class="navbar-item "
               href="/categories">Categories</a>
            
            <a class="navbar-item "
               href="/friendly-link">FriendlyLink</a>
            
            <a class="navbar-item "
               href="/aboutme">About</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="æœç´¢" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            <div class="navbar-item is-hoverable has-dropdown is-hidden-mobile is-hidden-tablet-only toc">
                <a class="navbar-item" title="ç›®å½•">
                    <i class="fa fa-list"></i>
                </a>
                <div class="navbar-dropdown is-right">
                    
                    
                    
                    
                    <a class="navbar-item" href="#ä¸€ã€Introduction">&nbsp;&nbsp;<b>ä¸€ã€Introduction</b></a>
                    
                    
                    
                    <a class="navbar-item" href="#1-è§£è€¦çš„æ³¨æ„åŠ›æœºåˆ¶">&nbsp;&nbsp;1. è§£è€¦çš„æ³¨æ„åŠ›æœºåˆ¶</a>
                    
                    
                    
                    <a class="navbar-item" href="#2-Enhanced-Mask-Decoder">&nbsp;&nbsp;2. Enhanced Mask Decoder</a>
                    
                    
                    
                    <a class="navbar-item" href="#3-SiFT">&nbsp;&nbsp;3. SiFT</a>
                    
                    
                    <hr class="navbar-divider">
                    
                    
                    <a class="navbar-item" href="#äºŒã€Background">&nbsp;&nbsp;<b>äºŒã€Background</b></a>
                    
                    
                    <hr class="navbar-divider">
                    
                    
                    <a class="navbar-item" href="#ä¸‰ã€Model-Architecture">&nbsp;&nbsp;<b>ä¸‰ã€Model Architecture</b></a>
                    
                    
                    
                    <a class="navbar-item" href="#1-Disentangled-Attention">&nbsp;&nbsp;1. Disentangled Attention</a>
                    
                    
                    
                    <a class="navbar-item" href="#2-Enhanced-Mask-Decoder-EMD">&nbsp;&nbsp;2. Enhanced Mask Decoder(EMD)</a>
                    
                    
                    <hr class="navbar-divider">
                    
                    
                    <a class="navbar-item" href="#å››ã€Scale-Invariant-Fine-tuning">&nbsp;&nbsp;<b>å››ã€Scale Invariant Fine-tuning</b></a>
                    
                    
                    <hr class="navbar-divider">
                    
                    
                    <a class="navbar-item" href="#äº”ã€å®éªŒç»“æœ">&nbsp;&nbsp;<b>äº”ã€å®éªŒç»“æœ</b></a>
                    
                    
                    <hr class="navbar-divider">
                    
                    
                    <a class="navbar-item" href="#å…­ã€å‚è€ƒæ–‡çŒ®">&nbsp;&nbsp;<b>å…­ã€å‚è€ƒæ–‡çŒ®</b></a>
                    
                </div>
            </div>
            
            
            <a class="navbar-item" title="GitHub" target="_blank" rel="noopener" href="https://github.com/aestheticisma">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section">
    <div class="container">
    <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            DeBERTa è®ºæ–‡è§£è¯»
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2021-11-24T10:21:44.000Z" itemprop="datePublished">11æœˆ 24 2021</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Paper-Reading/">Paper Reading</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            27 åˆ†é’Ÿ è¯»å®Œ (çº¦ 4032 å­—)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p style="text-indent:2em">
ã€ŠDeberta: decoding-Enhanced Bert with Disentangled Attentionã€‹ï¼Œè¯¥è®ºæ–‡æ¥è‡ª ICLR2021ï¼Œä½œè€…å›¢é˜Ÿä¸ºå¾®è½¯ï¼Œä¸»è¦ä»‹ç»äº†å…¶æå‡ºçš„ä¸€ä¸ªæ–°çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼šDeBERTaï¼Œè¯¥æ¨¡å‹ä»æ³¨æ„åŠ›è§£è€¦ï¼ˆdisentangled attentionï¼‰å’Œé¢„è®­ç»ƒé˜¶æ®µçš„è§£ç å¢å¼ºä¸¤æ–¹é¢å¯¹BERTç±»é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¹¶åœ¨SuperGLUEä¸Šé¦–æ¬¡è¶…è¶Šäººç±»åŸºå‡†ã€‚</p><span id="more"></span>

<p><a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=XPZIaotutsD">è®ºæ–‡åœ°å€</a>ã€<a target="_blank" rel="noopener" href="https://github.com/microsoft/DeBERTa">ä»£ç åœ°å€</a></p>
<h3 id="ä¸€ã€Introduction"><a href="#ä¸€ã€Introduction" class="headerlink" title="ä¸€ã€Introduction"></a>ä¸€ã€Introduction</h3><p style="text-indent:2em">
è¿™ç¯‡æ–‡ç« çš„åˆ›æ–°ç‚¹ä¸»è¦åœ¨ä¸‰ä¸ªéƒ¨åˆ†ï¼š1.ä½¿ç”¨äº†è§£è€¦çš„æ³¨æ„åŠ›æœºåˆ¶ï¼›2.å¯¹é¢„è®­ç»ƒé˜¶æ®µçš„MLMä»»åŠ¡çš„Decoderå±‚è¿›è¡Œäº†æ”¹è¿›ï¼›3.è®­ç»ƒæŠ€å·§ï¼ˆè™šæ‹Ÿå¯¹æŠ—è®­ç»ƒï¼‰</p>

<h4 id="1-è§£è€¦çš„æ³¨æ„åŠ›æœºåˆ¶"><a href="#1-è§£è€¦çš„æ³¨æ„åŠ›æœºåˆ¶" class="headerlink" title="1. è§£è€¦çš„æ³¨æ„åŠ›æœºåˆ¶"></a>1. è§£è€¦çš„æ³¨æ„åŠ›æœºåˆ¶</h4><p style="text-indent:2em">
æˆ‘ä»¬å›æƒ³ Transformer çš„ç»“æ„ï¼Œå¯¹äºä¸€ä¸ª token çš„è¡¨ç¤ºï¼Œæ˜¯åœ¨å…¶ word embedding çš„åŸºç¡€ä¸ŠåŠ ä¸Š position embedding æ‰€æ„æˆçš„ã€‚å½“ç„¶ Vaswani çš„ Transformer å¯¹äºä½ç½®åµŒå…¥ä½¿ç”¨çš„æ˜¯ç»å¯¹ä½ç½®ç¼–ç ï¼Œè¿™ç§æ–¹æ³•é¥±å—è´¨ç–‘ï¼Œåç»­åˆå‡ºç°äº†ç›¸å¯¹ä½ç½®ç¼–ç ç­‰ç­‰ã€‚è€ŒBERTä¹Ÿæ˜¯å¦‚æ­¤ï¼Œå…¶ word embedding ä¸º token embedding, position embedding å’Œ segment embedding ä¸‰è€…çš„ç›¸åŠ ã€‚</p>

<p><img src="/2021/11/24/deberta/bert_input.png" alt="bert_input.png"></p>
<p style="text-indent:2em">
è€Œæœ¬æ–‡æå‡ºçš„è§£è€¦çš„æ³¨æ„åŠ›æœºåˆ¶ï¼ˆdisentangled attention mechanismï¼‰å¯¹äºä½ç½®åµŒå…¥çš„å¤„ç†æ–¹å¼ä¸ä¸Šè¿°ä¸åŒï¼Œå³ä¸å†æ˜¯åœ¨ç¼–ç é˜¶æ®µç®€å•çš„å°†å†…å®¹åµŒå…¥ä¸ä½ç½®åµŒå…¥è¿›è¡Œç®€å•çš„ç›¸åŠ ä½œä¸ºä¸€ä¸ªå­—æˆ–è¯çš„è¡¨ç¤ºï¼Œè€Œæ˜¯å°†ä¸€ä¸ª token çš„è¡¨ç¤ºåˆ†ä¸ºä¸¤ä¸ªå‘é‡ï¼Œä¸€ä¸ªä¸º content embeddingï¼Œå¦ä¸€ä¸ªä¸º position embeddingï¼ŒäºŒè€…åˆ†åˆ«è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ï¼Œä¹‹åå†è¿›è¡Œç›¸åŠ ï¼Œå› æ­¤ç§°ä½œè§£è€¦çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚
</p>

<h4 id="2-Enhanced-Mask-Decoder"><a href="#2-Enhanced-Mask-Decoder" class="headerlink" title="2. Enhanced Mask Decoder"></a>2. Enhanced Mask Decoder</h4><p style="text-indent:2em">
åƒ BERT ä¸€æ ·ï¼ŒDeBERTa åœ¨é¢„è®­ç»ƒé˜¶æ®µä¹Ÿä½¿ç”¨äº† Masked Language Modelingï¼ˆMLMï¼‰ï¼ŒMLM å…¶å®æ˜¯ä¸€ä¸ªå®Œå½¢å¡«ç©ºä»»åŠ¡ï¼Œéœ€è¦è®©æ¨¡å‹å¯¹äºè¢« mask æ‰çš„ä½ç½®é¢„æµ‹å‡ºå…¶åŸæœ¬çš„å•è¯ã€‚ä½†åŸæœ¬çš„ BERT ä¸­çš„é¢„æµ‹éƒ¨åˆ†ï¼Œä¹Ÿå°±æ˜¯è§£ç éƒ¨åˆ†åªæœ‰ä¸€ä¸ªç®€å•çš„ softmax å±‚ï¼Œä½†æˆ‘ä»¬åœ¨è¿›è¡Œåç»­ä¸‹æ¸¸ä»»åŠ¡çš„å¾®è°ƒæ—¶å€™ï¼Œä¸€èˆ¬éƒ½ä¼šåŠ ä¸€ä¸ªç”¨äºç‰¹å®šä»»åŠ¡çš„è§£ç å™¨ï¼Œå› æ­¤æœ¬æ–‡æå‡ºäº†ä¸€ä¸ª Enhanced Mask Decoderï¼ˆEMDï¼‰ç”¨äºé¢„è®­ç»ƒé˜¶æ®µï¼Œä¸ºçš„å°±æ˜¯ç¼“è§£é¢„è®­ç»ƒä»»åŠ¡ä¸å¾®è°ƒä¹‹é—´çš„ä¸åŒ¹é…ã€‚
</p>

<h4 id="3-SiFT"><a href="#3-SiFT" class="headerlink" title="3. SiFT"></a>3. SiFT</h4><p style="text-indent:2em">
æ„Ÿè§‰è¿™ç®—æ˜¯ä¸€ä¸ªå¾®è°ƒçš„è®­ç»ƒæŠ€å·§å§ï¼Œä½œè€…é’ˆå¯¹è™šæ‹Ÿå¯¹æŠ—è®­ç»ƒï¼ˆvirtual adversarial trainingï¼‰è¿›è¡Œäº†å°éƒ¨åˆ†çš„è°ƒæ•´ï¼Œæ–°æ–¹æ³•ç§°ä¸º Scale-invariant-Fine-Tuningï¼ˆSiFTï¼‰ã€‚åœ¨é’ˆå¯¹å°†é¢„è®­ç»ƒæ¨¡å‹ç”¨äºä¸‹æ¸¸ä»»åŠ¡çš„Fine-tuneé˜¶æ®µåŠ å…¥ SiFT å¯ä»¥å¢å¼ºæ¨¡å‹çš„æ³›åŒ–æ€§ã€‚
</p>

<h3 id="äºŒã€Background"><a href="#äºŒã€Background" class="headerlink" title="äºŒã€Background"></a>äºŒã€Background</h3><p>è¯´å®è¯èƒŒæ™¯è¿™ä¸€å—å†…å®¹å¹¶ä¸å¤šï¼Œä¹Ÿæ²¡æœ‰ä»€ä¹ˆå€¼å¾—ä»‹ç»çš„ï¼Œä¸€å…±å°±ä¸¤ä¸ªï¼Œç¬¬ä¸€ä¸ªå°±æ˜¯ç›®å‰å„å¤§é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹æ‰€ä½¿ç”¨çš„ Transformer æ¨¡å‹ç»“æ„ï¼Œå¦ä¸€ä¸ªå°±æ˜¯ MLMã€‚å…³äº Transformerï¼Œå¯ä»¥çœ‹æˆ‘çš„<a href="https://aestheticisma.github.io/2021/10/11/transformer/">ä¸Šä¸€ç¯‡æ–‡ç« </a>ï¼Œä¸‹é¢ç®€å•ç”¨è¯­è¨€å’Œæ•°å­¦å…¬å¼æè¿°ä¸‹ MLMï¼š</p>
<p style="text-indent:2em">
å¯¹äºç»™å®šä¸€ä¸ªåºåˆ— $ \textit{X} = \lbrace x_i \rbrace $ï¼Œæˆ‘ä»¬é€šè¿‡éšæœº mask æ‰å…¶ 15% çš„ tokensï¼Œå°† $\textit{X}$ å˜ä¸º $\tilde{X}$ï¼Œè®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œæ¨¡å‹å‚æ•°é›†åˆä¸º $\theta$ï¼Œæˆ‘ä»¬è®©æ¨¡å‹åŸºäº $\tilde{X}$ æ¥é¢„æµ‹è¢« mask æ‰çš„ $\tilde{x}$ï¼Œæ•°å­¦æè¿°ä¸ºï¼š$$ \mathop{max}\limits_{\theta}logp_{\theta}(\textit{X} | \tilde{X}) = \mathop{max}\limits_{\theta}\sum\limits_{i\in\mathcal{C}}logp_{\theta}(\tilde{x_i} = x_i | \tilde{X}) \tag{1}$$
$\mathcal{C}$ä»£è¡¨åºåˆ—ä¸­è¢« mask æ‰çš„ token çš„ç´¢å¼•ï¼Œå½“ç„¶è¿™é‡Œå°±ä¸å…·ä½“å±•å¼€å…·ä½“ mask çš„è§„åˆ™äº†ã€‚
</p>

<h3 id="ä¸‰ã€Model-Architecture"><a href="#ä¸‰ã€Model-Architecture" class="headerlink" title="ä¸‰ã€Model Architecture"></a>ä¸‰ã€Model Architecture</h3><p style="text-indent:2em">
åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬è¯¦ç»†ä»‹ç»ä¸€ä¸‹è¿™ç¯‡è®ºæ–‡æ‰€æå‡ºçš„ DeBERTa çš„æ¨¡å‹ç»“æ„ï¼Œä¸»è¦åˆ†ä¸º Disentangled Attention å’Œ Enhanced Mask Decoder(EMD) ä¸¤ä¸ªéƒ¨åˆ†ã€‚
</p>

<h4 id="1-Disentangled-Attention"><a href="#1-Disentangled-Attention" class="headerlink" title="1. Disentangled Attention"></a>1. Disentangled Attention</h4><p style="text-indent:2em">
å¦‚å‰æ‰€è¿°ï¼Œæ‰€è°“è§£è€¦çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå³æ˜¯å°†è¯åµŒå…¥è§£è€¦ä¸ºå†…å®¹åµŒå…¥å’Œä½ç½®åµŒå…¥ä¸¤ä¸ªå‘é‡ï¼Œæ–‡ä¸­å°æ ‡é¢˜è¿™ä¹ˆæ¥æ¦‚æ‹¬å®ƒï¼š"A Two-Vector Approach to Content and Position Embedding"ã€‚é‚£ä¹ˆå…·ä½“æ˜¯æ€ä¹ˆåšçš„å‘¢ï¼Ÿ
</p>

<p style="text-indent:2em">
å¯¹äºä¸€ä¸ªåºåˆ—ä¸­ä½ç½®ä¸º $i$ çš„ token $x_i$ï¼Œæˆ‘ä»¬ç”¨ $\lbrace \textit{H}_i \rbrace$ å’Œ $\lbrace \textit{P}_{i|j} \rbrace $ ä¸¤ä¸ªå‘é‡æ¥è¡¨ç¤ºå®ƒï¼Œå‰è€…ä»£è¡¨å®ƒçš„å†…å®¹ï¼ˆcontentï¼‰åµŒå…¥ï¼Œåè€…ä»£è¡¨å®ƒå…³äºåºåˆ—ä¸­ä½ç½®ä¸º $j$ çš„ token $x_j$ çš„ç›¸å¯¹ä½ç½®ï¼ˆrelative positionï¼‰åµŒå…¥ã€‚åœ¨ä¹‹å‰æˆ‘ä»¬éƒ½æ˜¯å°†ä¸¤ä¸ªå‘é‡ç›¸åŠ å¾—åˆ°çš„ä¸€ä¸ªå’Œå‘é‡ä½œä¸º token çš„ç¼–ç è¡¨ç¤ºï¼Œä½†ç°åœ¨æˆ‘ä»¬æ¢ä¸€ä¸ªç©æ³•ï¼Œæˆ‘ä»¬å°† content å’Œ position çœ‹ä½œç‹¬ç«‹çš„ä¸ªä½“ï¼Œè®©ä»–ä»¬éƒ½å‚ä¸åˆ° attention çš„è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œé‚£ä¹ˆä¹Ÿå°±å¾—åˆ°äº†ä¸‹é¢çš„å…¬å¼ï¼š$$ \textit{A}_{i, j} =  \lbrace \textit{H}_i, \textit{P}_{i|j} \rbrace \times {\lbrace \textit{H}_j, \textit{P}_{j|i} \rbrace}^{T} \\ = \textit{H}_i\textit{H}_j^{T} + \textit{H}_i\textit{P}_{j|i}^{T} + \textit{P}_{i|j}\textit{H}_j^{T} + \textit{P}_{i|j}\textit{P}_{j|i}^{T} \tag{2}$$
</p>

<p style="text-indent:2em">
å¦‚å…¬å¼ï¼ˆ2ï¼‰æ‰€ç¤ºï¼Œä½¿ç”¨æ³¨æ„åŠ›è§£è€¦çš„æ–¹æ³•å¯ä»¥å°†ä¸€ä¸ª word pair çš„ attention æƒé‡çœ‹ä½œå››ä¸ªåˆ†é‡çš„å’Œï¼šcontent-to-content, content-to-position, position-to-content å’Œ position-to-positionã€‚åœ¨è¿™é‡Œä½œè€…æŒ‡å‡ºï¼Œç°æœ‰çš„ç›¸å¯¹ä½ç½®åµŒå…¥çš„æ–¹æ³•<sup>[1]</sup>åªåœ¨ Attention è®¡ç®—æ—¶ç”¨äº†åˆ†ç¦»çš„ Embedding çŸ©é˜µï¼Œè¿™ç§åšæ³•ç›¸å½“äºåªç”¨åˆ°äº†å‰é¢æåˆ°çš„å››ä¸ªåˆ†é‡ä¸­çš„å‰ä¸¤ä¸ªã€‚ä½†ä½œè€…è®¤ä¸ºä¸€ä¸ª word pair ä¹‹é—´çš„ attention æƒé‡ä¸ä»…ä¾èµ–äºå…¶ contentï¼Œå®ƒä»¬ä¹‹é—´çš„ç›¸å¯¹ä½ç½®å…³ç³»ä¹Ÿè‡³å…³é‡è¦ï¼Œå› æ­¤åŠ å…¥äº†ç¬¬ä¸‰ä¸ªåˆ†é‡ï¼Œä¹Ÿå°±æ˜¯ position-to-contentã€‚æœ€åä¸¢å¼ƒäº†ç¬¬å››ä¸ªåˆ†é‡ï¼ˆå› ä¸ºå·²ç»æ˜¯ç›¸å¯¹ä½ç½®å…³ç³»äº†ï¼Œä½ç½®å’Œä½ç½®ä¹‹é—´çš„å…³ç³»å·²ç»æä¾›ä¸äº†é¢å¤–çš„ä¿¡æ¯äº†ï¼Œæ‰€ä»¥ä¸¢å¼ƒäº†è¿™ä¸ªåˆ†é‡ï¼‰ã€‚
</p>

<p style="text-indent:2em">
åœ¨è¿™é‡Œæˆ‘è§‰å¾—æœ‰å¿…è¦ç®€å•ä»‹ç»ä¸€ä¸‹Shawç­‰äºº<sup>[1]</sup>æå‡ºçš„åœ¨ Transformer ä¸­ä½¿ç”¨ç›¸å¯¹ä½ç½®åµŒå…¥çš„æ–¹æ³•ã€‚æˆ‘ä»¬å°†è¾“å…¥çš„åºåˆ— $ \textit{X} $ çœ‹ä½œä¸€ä¸ªæœ‰å‘å…¨è¿æ¥å›¾ï¼Œå¯¹äº $ \textit{X} $ ä¸­çš„å…ƒç´  $x_i$ å’Œ $x_j$ ä¹‹é—´çš„è¾¹é€šè¿‡ä¸¤ä¸ªå‘é‡ $a_{ij}^K, a_{ij}^V \in \mathbb{R}^{d_a}$ æ¥è¡¨ç¤ºï¼Œå¹¶ä¸”è¿™äº›å‘é‡åœ¨å¤šä¸ª head ä¹‹é—´å…±äº«ï¼Œ$d_a = d_z$ã€‚é€šè¿‡å¼•å…¥è¾¹çš„ç‰¹å¾è¡¨ç¤ºï¼Œå°† Vaswani ç±» Transformer ä¸­çš„ self-attention è®¡ç®—æ–¹å¼ä¿®æ”¹ä¸ºï¼š
$$ z_i = \sum_{j=1}^n\alpha_{ij}(x_jW^V + a_{ij}^V) $$
$$ \alpha_{ij} = \frac{\text{exp}\ e_{ij}}{\sum_{k=1}^n\text{exp}\ e_{i,k}} $$
$$ e_{ij} = \frac{x_iW^Q(x_jW^K + a_{ij}^K)^T}{\sqrt{d_k}} $$
</p>
<p style="text-indent:2em">
è€Œ $ a_{ij}^K $ å’Œ $ a_{ij}^V $ é€šè¿‡ä»¥ä¸‹å…¬å¼å¾—å‡ºï¼š
$$ a_{ij}^K = W_{clip(j-i, k)^K} $$
$$ a_{ij}^V = W_{clip(j-i, k)^V} $$
$$ clip(x, k) = max(-k, min(x, k)) \tag{3}$$
æ–‡ä¸­æåŠçš„å·²ç»å­˜åœ¨çš„ç›¸å¯¹ä½ç½®åµŒå…¥çš„æ–¹æ³•å°±ä»‹ç»åˆ°è¿™é‡Œï¼Œä¸‹é¢ç»§ç»­ä»‹ç»æœ¬ç¯‡æ–‡ç« æå‡ºçš„ Disentangled Attentionã€‚
</p>

<p style="text-indent:2em">
ä¸Šæ¥å…¬å¼ï¼ˆ2ï¼‰ï¼Œæˆ‘ä»¬å–å…¶å‰ä¸‰ä¸ªåˆ†é‡ä½œä¸ºæ³¨æ„åŠ›æƒé‡ï¼Œé¦–å…ˆå›é¡¾ä¸€ä¸‹æ ‡å‡†çš„å•å¤´ï¼ˆsingle headï¼‰è‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰è¿ç®—<sup>[2]</sup>ã€‚
$$ Q = HW_q,\ K = HW_k,\ V = HW_v,\ A = \frac{QK^T}{\sqrt{d}} $$
$$ H_o = softmax(A)V $$
$ H \in \mathbb{R}^{N \times d} $ è¡¨ç¤ºè¾“å…¥çš„éšå±‚å‘é‡ï¼Œ$ H_o \in \mathbb{R}^{N \times d} $ è¡¨ç¤º self-attention çš„è¾“å‡ºï¼Œ$ W_q,\ W_k,\ W_v \in \mathbb{R}^{d \times d} $ï¼ŒNä»£è¡¨è¾“å…¥åºåˆ—çš„é•¿åº¦ã€‚
</p>

<p style="text-indent:2em">
å‰é¢æåˆ°ï¼Œåœ¨æœ¬ç¯‡è®ºæ–‡ä¸­ä¸€ä¸ª token çš„è¡¨ç¤ºåˆ†åˆ«ç”¨ content å’Œ position ä¸¤ä¸ªå‘é‡è¡¨ç¤ºï¼Œå› æ­¤ä½¿ç”¨äº†ä¸¤å¥— Qå’ŒKï¼Œä¸‹é¢ç”¨ $Q_c,\ K_c,\ V_c$ è¡¨ç¤ºå…³äº content çš„çŸ©é˜µï¼Œ$Q_r,\ K_r$ è¡¨ç¤ºå…³äº position çš„çŸ©é˜µã€‚åŒæ—¶ï¼Œ$W_{q, c},\ W_{k, c},\ W_{v, c} \in \mathbb{R}^{d \times d} $ ç”¨æ¥è¡¨ç¤ºå…³äº content çš„ projection matricesï¼Œ$W_{q, r},\ W_{k, r} \in \mathbb{R}^{d \times d}$ ç”¨æ¥è¡¨ç¤ºå…³äº position çš„ projection matricesã€‚é¢å¤–çš„ï¼Œå®šä¹‰äº†ä¸€ä¸ªç”¨äºå­˜å‚¨ä½ç½®åµŒå…¥çš„çŸ©é˜µ $ P \in \mathbb{R}^{2k \times d} $ã€‚é‚£ä¹ˆå¯ä»¥å¾—åˆ°å¦‚ä¸‹å‡ ä¸ªå…¬å¼ï¼š
$$ Q_c = HW_{q,c},\ K_c = HW_{k,c},\ V_c = HW_{v,c},\ Q_r = PW_{q,r},\ K_r = PW_{k,r} $$
$$ \tilde{A}_{i,j} = \underbrace{Q_i^c{K_j^c}^T}_{(a)content-to-content} + \underbrace{Q_i^c{K_{\delta(i,j)}^r}^T}_{(b)content-to-position} + \underbrace{K_j^c{Q_{\delta(j,i)}^r}^T}_{(c)position-to-content} $$
$$ H_o = softmax(\frac{\tilde{A}}{\sqrt{3d}})V_c $$
</p>

<p style="text-indent:2em">
è¯´å®è¯ï¼Œç¬¬ä¸‰ä¸ªåˆ†é‡ä¸ç”¨ $\delta(i,j)$ è€Œæ˜¯ $\delta(j,i)$ æˆ‘æ²¡æœ‰æƒ³æ˜ç™½ä¸ºä»€ä¹ˆï¼Œè®ºæ–‡ä¸­å…³äºå®ƒçš„è§£é‡Šåªæœ‰ä¸€å¥è¯ï¼šThis is because for a given position
i, position-to-content computes the attention weight of the key content at j with respect to the
query position at i, thus the relative distance is $\delta(j,i)$. $\delta(i,j)$ çš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š
$$ \delta(i,j) = \begin{cases} 0 &amp; \text{for $i-j\leq-k$} \\
                    2k-1 &amp; \text{for $i-j\geq k$} \\
                    i-j+k &amp; \text{others.} \end{cases}$$
</p>

<p style="text-indent:2em">
é™¤æ­¤ä¹‹å¤–ï¼Œå…·ä½“å®ç°çš„æ—¶å€™ï¼Œä½œè€…å¹¶æ²¡æœ‰åƒ[1]ä¸­ä¸€æ ·å­˜å‚¨äº†æ‰€æœ‰çš„ç›¸å¯¹ä½ç½®ç¼–ç ï¼ˆéœ€è¦ $O(N^2d)$ çš„ç©ºé—´å¤æ‚åº¦ï¼‰ï¼Œè€Œæ˜¯åªæ˜¯å­˜å‚¨äº†ä¸Šè¿°çš„ $P \in \mathbb{R}^{2k \times d}$ï¼Œä¹Ÿå¯ä»¥ç†è§£ä¸ºå­˜å‚¨äº† $K^r \in \mathbb{R}^{2k \times d}$ å’Œ $Q_r \in \mathbb{R}^{2k \times d} $ï¼Œç”±äºæœ€åçš„ $\delta(i,j)$ å‡½æ•°è®¡ç®—çš„å€¼åŸŸå…¶å®æ˜¯ [0, 2k-1] çš„ï¼Œå› æ­¤åœ¨çŸ©é˜µä¹˜æ³•è®¡ç®—å®Œæˆåï¼Œé€šè¿‡ç´¢å¼•å–ç›¸åº”ä½ç½®çš„ç»“æœå³å¯ï¼Œä»è€Œç©ºé—´å¤æ‚åº¦é™ä½åˆ°äº† $O(kd)$ã€‚
</p>

<h4 id="2-Enhanced-Mask-Decoder-EMD"><a href="#2-Enhanced-Mask-Decoder-EMD" class="headerlink" title="2. Enhanced Mask Decoder(EMD)"></a>2. Enhanced Mask Decoder(EMD)</h4><p style="text-indent:2em">
åœ¨è¿™ä¸€éƒ¨åˆ†ä½œè€…é¦–å…ˆé€šè¿‡ä¸€ä¸ªä¾‹å­: "a new <strong>store</strong> opened beside the new <strong>mall</strong>." å¼•å‡ºä¸»æ—¨ï¼Œæˆ‘ä»¬è®©é¢„è®­ç»ƒæ¨¡å‹é€šè¿‡ MLM å»é¢„æµ‹å•è¯ â€œstoreâ€ å’Œ â€œmallâ€ï¼Œä½†è¿™ä¸¤ä¸ªå•è¯çš„éƒ¨åˆ†ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆè¿™é‡ŒæŒ‡ç›¸å¯¹ä½ç½®å’Œå‘¨å›´è¯ï¼‰æ˜¯ç›¸åŒçš„ï¼Œæ¯”å¦‚éƒ½ä½äºâ€œnewâ€è¿™ä¸ªå•è¯çš„åé¢ä¸”ä¸å…¶ç›¸å¯¹ä½ç½®ç›¸åŒï¼Œå› æ­¤è¿™å°±ç»™æ¨¡å‹åŒºåˆ†ä¸¤ä¸ªå•è¯é€ æˆäº†å›°éš¾ï¼Œä½†è¿™å¥è¯çš„ä¸»è¯­æ˜¯â€œstoreâ€è€Œä¸æ˜¯â€œmallâ€ï¼Œå› æ­¤ä½œè€…è®¤ä¸ºç»å¯¹ä½ç½®ä¿¡æ¯ä¹Ÿæ˜¯å¾ˆé‡è¦çš„ã€‚ä½†åœ¨ BERT ä¸­ï¼Œç»å¯¹ä½ç½®ä¿¡æ¯æ˜¯åŠ åœ¨åºåˆ—çš„è¾“å…¥å‘é‡ä¸­çš„ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å·²ç»ä¿®æ”¹æˆäº†ç›¸å¯¹ä½ç½®ä¿¡æ¯ï¼Œé‚£ä¹ˆè¿˜æ€ä¹ˆæŠŠç»å¯¹ä½ç½®ä¿¡æ¯åŠ å…¥è¿›å»å‘¢ï¼Ÿæ—¢ç„¶æˆ‘ä»¬è¿™é‡Œçš„ç»å¯¹ä½ç½®ä¿¡æ¯æ˜¯ä¸ºäº†è®© MLM æ›´å¥½çš„é¢„æµ‹è¢« mask æ‰çš„å•è¯ï¼Œé‚£ä½œè€…å°±å°†ç»å¯¹ä½ç½®ä¿¡æ¯åŠ åœ¨äº†æœ€å softmax ä¹‹å‰ï¼ˆå‡†ç¡®çš„è¯´æ˜¯ä¹‹å‰çš„è§£ç å™¨çš„è¾“å…¥ä¸Šï¼‰ã€‚
</p>

<p style="text-indent:2em">
é™¤äº†ç»å¯¹ä½ç½®ä¿¡æ¯ä¹‹å¤–ï¼Œä½œè€…è¿˜è®¤ä¸ºå¯¹äºç‰¹å®šçš„ä¸‹æ¸¸ä»»åŠ¡ï¼Œæˆ‘ä»¬ä¸€èˆ¬ä¼šåœ¨é¢„è®­ç»ƒæ¨¡å‹åé¢åŠ ä¸€ä¸ªå…³äºç‰¹å®šä»»åŠ¡çš„è§£ç å™¨ï¼Œä½†æ˜¯é¢„è®­ç»ƒé˜¶æ®µçš„ MLM å´åªæœ‰ä¸€ä¸ªsoftmaxå±‚ï¼ˆé™¤äº†å‰é¢é‚£ä¸€äº› dense å’Œ LNï¼‰ï¼Œè¿™éš¾å…ä¼šé€ æˆä¸€äº›ä¸åŒ¹é…ï¼Œå› æ­¤å°†åŸæ¥çš„åªæœ‰ softmax å±‚å˜æˆäº†ä¸¤å±‚çš„ transformer encoder layer + softmaxã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
</p>

<p><img src="/2021/11/24/deberta/decoder_layer.png" alt="decoder_layer"></p>
<p style="text-indent:2em">
åˆšçœ‹åˆ°è¿™å¹…å›¾å¯èƒ½æœ‰ç‚¹æ™•ï¼Œï¼ˆaï¼‰ä»£è¡¨çš„å°±æ˜¯åŸå§‹ BERT çš„ MLM çš„ç»“æ„ï¼Œå¯ä»¥çœ‹åˆ°ä» BERT çš„æœ€åä¸€å±‚ Transformer encoder layer å‡ºæ¥çš„å‘é‡ç›´æ¥è¾“å…¥è‡³ MLM çš„è§£ç å™¨ï¼›è€Œï¼ˆbï¼‰è¡¨ç¤ºçš„å°±æ˜¯è®ºæ–‡ä¿®æ”¹åçš„ EMDï¼Œå…¶ä¸­ I å¯ä»¥ä»£è¡¨å¤šç§ä¿¡æ¯ï¼š1.ç»å¯¹ä½ç½®ä¿¡æ¯ï¼›2.ç»å¯¹ä½ç½®ä¿¡æ¯+éšå±‚å‘é‡ï¼›3.éšå±‚å‘é‡ï¼ˆå‰ä¸€å±‚çš„è¾“å‡ºï¼‰ã€‚$x_n$ ä»£è¡¨å•å…ƒå¾ªç¯ n æ¬¡ï¼Œæ‰€ä»¥å½“ n = 1ï¼ŒI = H æ—¶ï¼ŒEMD å…¶å®å°±å’Œ BERT çš„è§£ç å™¨æ˜¯ä¸€æ ·çš„ã€‚å¹¶ä¸”ä½œè€…æåˆ°ï¼Œåœ¨ DeBERTa ä¸­ï¼Œä»–ä»¬å°† n è®¾ç½®ä¸ºäº† 2ï¼Œå¹¶ä¸” n ä¸ªå•å…ƒçš„å‚æ•°æ˜¯å…±äº«çš„ã€‚
</p>

<p style="text-indent:2em">
ä½†åˆ°è¿™é‡Œæˆ‘è¿˜æ˜¯å¾ˆç–‘æƒ‘çš„ï¼Œé‚£ä½œä¸ºé¢„è®­ç»ƒæ¨¡å‹çš„é‚£ä¸€äº› Transformer encoder layer æœ‰å¤šå°‘å±‚å‘¢ï¼ŸåŠ ä¸Šè¿™ä¸ª EMDï¼Œä¸ä¼šé€ æˆå‚æ•°é‡çš„å¢é•¿å—ï¼Ÿè¿™äº›é—®é¢˜åœ¨è®ºæ–‡å¼€æºçš„ä»£ç ä¸­æˆ‘æ‰¾åˆ°äº†ç­”æ¡ˆã€‚
</p>

<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">emd_context_layer</span>(<span class="hljs-params">self, encoder_layers, z_states, attention_mask, encoder, target_ids, input_ids, input_mask, relative_pos=<span class="hljs-literal">None</span></span>):</span></span><br><span class="line">    <span class="hljs-keyword">if</span> attention_mask.dim()&lt;=<span class="hljs-number">2</span>:</span><br><span class="line">        extended_attention_mask = attention_mask.unsqueeze(<span class="hljs-number">1</span>).unsqueeze(<span class="hljs-number">2</span>)</span><br><span class="line">        att_mask = extended_attention_mask.byte()</span><br><span class="line">        attention_mask = att_mask*att_mask.squeeze(-<span class="hljs-number">2</span>).unsqueeze(-<span class="hljs-number">1</span>)</span><br><span class="line">    <span class="hljs-keyword">elif</span> attention_mask.dim()==<span class="hljs-number">3</span>:</span><br><span class="line">        attention_mask = attention_mask.unsqueeze(<span class="hljs-number">1</span>)</span><br><span class="line">    target_mask = target_ids&gt;<span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-comment"># å– deberta çš„å€’æ•°ç¬¬äºŒå±‚çš„éšå±‚è¾“å‡ºå‘é‡</span></span><br><span class="line">    hidden_states = encoder_layers[-<span class="hljs-number">2</span>]</span><br><span class="line">    <span class="hljs-comment"># ä»è¿™é‡Œå¼€å§‹ EMD çš„è®¡ç®—</span></span><br><span class="line">    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.position_biased_input: </span><br><span class="line">        <span class="hljs-comment"># EMD çš„ transformer encoder layer æœ‰ä¸¤ä¸ª \</span></span><br><span class="line">        <span class="hljs-comment"># ä½†éƒ½æ˜¯ç”¨çš„ deberta çš„æœ€åä¸€å±‚çš„ encoder layerï¼Œå› æ­¤è®ºæ–‡ä¸­è¯´å‚æ•°å…±äº«</span></span><br><span class="line">        layers = [encoder.layer[-<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)]</span><br><span class="line">        <span class="hljs-comment"># `z_status`æœ€å¼€å§‹ä¼ å…¥è¿›æ¥çš„æ˜¯ç»å¯¹ä½ç½®ä¿¡æ¯ï¼Œç°åœ¨åŠ ä¸Šä¸Šä¸€å±‚çš„è¾“å‡º</span></span><br><span class="line">        z_states +=  hidden_states</span><br><span class="line">        query_states = z_states</span><br><span class="line">        query_mask = attention_mask</span><br><span class="line">        outputs = []</span><br><span class="line">        rel_embeddings = encoder.get_rel_embedding()</span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># æ³¨æ„åªæœ‰ EMD çš„ç¬¬ä¸€å±‚ layer æ‰ä¼ å…¥äº†ç»å¯¹ä½ç½®ä¿¡æ¯ \</span></span><br><span class="line">        <span class="hljs-comment"># ç¬¬äºŒå±‚çš„ layer ä¼ å…¥çš„æ˜¯ä¸Šä¸€å±‚çš„è¾“å‡º</span></span><br><span class="line">        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> layers:</span><br><span class="line">            <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> pass relative pos ids</span></span><br><span class="line">            output = layer(hidden_states, query_mask, return_att=<span class="hljs-literal">False</span>, query_states = query_states, relative_pos=relative_pos, rel_embeddings = rel_embeddings)</span><br><span class="line">            query_states = output</span><br><span class="line">            outputs.append(query_states)</span><br><span class="line">    <span class="hljs-keyword">else</span>:</span><br><span class="line">        outputs = [encoder_layers[-<span class="hljs-number">1</span>]]</span><br><span class="line">    </span><br><span class="line">    _mask_index = (target_ids&gt;<span class="hljs-number">0</span>).view(-<span class="hljs-number">1</span>).nonzero().view(-<span class="hljs-number">1</span>)</span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">flatten_states</span>(<span class="hljs-params">q_states</span>):</span></span><br><span class="line">        q_states = q_states.view((-<span class="hljs-number">1</span>, q_states.size(-<span class="hljs-number">1</span>)))</span><br><span class="line">        q_states = q_states.index_select(<span class="hljs-number">0</span>, _mask_index)</span><br><span class="line">        <span class="hljs-keyword">return</span> q_states</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> [flatten_states(q) <span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> outputs]</span><br></pre></td></tr></tbody></table></figure>
<p style="text-indent:2em">
æ ¹æ®æºç ï¼Œæˆ‘ä»¬å¯ä»¥å¤§è‡´æ¨æ–­å‡ºï¼Œå¯¹æ ‡ä¸€ä¸ªå…·æœ‰ 12 å±‚ Transformer encoder layer çš„ BERTï¼ŒDeBERTa çš„ Transformer encoder layer æœ‰ 11 å±‚ï¼Œä½†æœ‰é¢å¤–çš„ 1 å±‚ ç”¨äº EMDï¼Œå¹¶ä¸”å¤ç”¨è¿™ 1 å±‚ä¸€æ¬¡ï¼Œç›¸å½“äºå¾ªç¯ä¸¤æ¬¡è¯¥å±‚ï¼Œæœ€åæ•´ä¸ª DeBERTa çš„å‚æ•°é‡å…¶å®è¿˜æ˜¯ 12 å±‚ï¼Œå‚æ•°è§„æ¨¡ä¸ BERT ä¸€è‡´ï¼Œä¸å¾—ä¸è¯´ç¡®å®å·§å¦™ã€‚å…¶ä»–å…³äº EMD çš„è¾“å…¥ I çš„é—®é¢˜å‡åœ¨ä»£ç ä¸­ä»¥ä¸­æ–‡æ³¨é‡Šæ ‡æ³¨å‡ºæ¥äº†ã€‚
</p>

<h3 id="å››ã€Scale-Invariant-Fine-tuning"><a href="#å››ã€Scale-Invariant-Fine-tuning" class="headerlink" title="å››ã€Scale Invariant Fine-tuning"></a>å››ã€Scale Invariant Fine-tuning</h3><p style="text-indent:2em">
è¿™éƒ¨åˆ†ä¸»è¦ä»‹ç»äº†ä¸€ç§ç”¨äº Fine-tuning é˜¶æ®µçš„è®­ç»ƒæŠ€å·§ï¼Œå€Ÿé‰´äºè™šæ‹Ÿå¯¹æŠ—è®­ç»ƒç®—æ³•ï¼ˆvirtual adversarial training algorithmï¼‰ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§è§„æ¨¡ä¸å˜å¾®è°ƒï¼ˆScale Invariant Fine-tuningï¼ŒSiFTï¼‰ã€‚è™šæ‹Ÿå¯¹æŠ—è®­ç»ƒæ˜¯ä¸€ç§æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„æ­£åˆ™åŒ–æ–¹æ³•ï¼Œå®ƒé€šè¿‡æé«˜æ¨¡å‹å¯¹å¯¹æŠ—æ€§ç¤ºä¾‹çš„é²æ£’æ€§æ¥å®ç°ï¼Œå¯¹æŠ—æ€§ç¤ºä¾‹æ˜¯é€šè¿‡å¯¹è¾“å…¥è¿›è¡Œå°å¹…æ‰°åŠ¨è€Œåˆ›å»ºçš„ã€‚
</p>
<p style="text-indent:2em">
ä½œè€…æŒ‡å‡ºï¼Œå¯¹äº NLP ä»»åŠ¡ï¼Œæ‰°åŠ¨åº”ç”¨äºè¯åµŒå…¥è€Œä¸æ˜¯åŸå§‹è¯åºåˆ—ã€‚ç„¶è€Œï¼ŒåµŒå…¥å‘é‡çš„å–å€¼èŒƒå›´ï¼ˆèŒƒæ•°ï¼‰åœ¨ä¸åŒçš„è¯å’Œæ¨¡å‹ä¹‹é—´æœ‰æ‰€ä¸åŒã€‚å¯¹äºå…·æœ‰æ•°åäº¿ä¸ªå‚æ•°çš„æ›´å¤§æ¨¡å‹ï¼Œæ–¹å·®ä¼šå˜å¾—æ›´å¤§ï¼Œä»è€Œå¯¼è‡´å¯¹æŠ—æ€§è®­ç»ƒçš„ä¸€äº›ä¸ç¨³å®šæ€§ã€‚è€Œå¯¹äº SiFT çš„å¯¹äº VAT çš„æ”¹è¿›å°±ä¸€å¥è¯æè¿°ï¼šâ€œapplying the perturbations to the normalized word embeddingsâ€ï¼Œä¹Ÿå°±æ˜¯è¯´åœ¨ç»è¿‡æ ‡å‡†åŒ–åçš„ word embedding ä¸Šæ·»åŠ éšæœºæ‰°åŠ¨ï¼Œä»è€Œå°±å¯ä»¥é™å®šæ‰°åŠ¨çš„â€æ–¹å·®â€œçš„å€¼çš„èŒƒå›´ä¸ä¼šå¤ªå¤§ï¼Œä¹Ÿä¸ä¼šå¤ªå°<sup>[3]</sup>ã€‚
</p>

<p style="text-indent:2em">
ä½† SiFT ç®—æ³•åªåº”ç”¨åˆ°äº† DeBERTa1.5B è¿™ä¸ªæ¨¡å‹ä¸Šé¢ï¼Œæˆ‘ä»¬ç›´æ¥çœ‹ç»“æœã€‚
</p>

<p><img src="/2021/11/24/deberta/SiFT_results.png" alt="SiFT_results"><br>å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ DeBERTa1.5B ä¸ŠåŠ å…¥ SiFT åï¼Œæ€§èƒ½æœ‰äº†è¿›ä¸€æ­¥çš„æå‡ã€‚</p>
<h3 id="äº”ã€å®éªŒç»“æœ"><a href="#äº”ã€å®éªŒç»“æœ" class="headerlink" title="äº”ã€å®éªŒç»“æœ"></a>äº”ã€å®éªŒç»“æœ</h3><p>è¿™éƒ¨åˆ†çš„æ¶ˆèå®éªŒåšçš„æŒºå……åˆ†çš„ï¼Œç´¯äº†ï¼Œå°±ä¸è´´å›¾äº†ï¼Œå¤§ä¼™è‡ªå·±å»åŸæ–‡çœ‹å§â€¦</p>
<h3 id="å…­ã€å‚è€ƒæ–‡çŒ®"><a href="#å…­ã€å‚è€ƒæ–‡çŒ®" class="headerlink" title="å…­ã€å‚è€ƒæ–‡çŒ®"></a>å…­ã€å‚è€ƒæ–‡çŒ®</h3><p>[1] Shaw P, Uszkoreit J, Vaswani A. Self-Attention with Relative Position Representations[C]//Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers). 2018: 464-468.<br>[2] Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[C]//Advances in neural information processing systems. 2017: 5998-6008.<br>[3] <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/395086745">https://zhuanlan.zhihu.com/p/395086745</a></p>
<style>
    img {
        width: 55%;
        height: 55%;
        margin: auto;
        display: table-cell;
        text-align: center;
    }
</style>
</body></html>
    
    </div>
    
    
    <div class="columns is-mobile is-multiline article-nav">
        <span class="column is-12-mobile is-half-desktop  article-nav-prev">
            
            <a href="/2022/02/02/tarjan/">å›¾è®º(1)ï¼šä½¿ç”¨tarjanç®—æ³•è§£å†³å¯»æ‰¾æ— å‘å›¾è¿é€šå›¾ä¸­çš„å‰²ç‚¹ä¸æ¡¥</a>
            
        </span>
        <span class="column is-12-mobile is-half-desktop  article-nav-next">
            
            <a href="/2021/10/11/transformer/">Transformer è§£è¯»</a>
            
        </span>
    </div>
    
</article>




    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2019-2022 æµå²š&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        target="_blank" rel="noopener" href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" target="_blank" rel="noopener" href="https://github.com/aestheticisma">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("zh-CN");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
</script>

    
    
    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    



<script src="/js/script.js"></script>


    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="ç«™å†…æœç´¢" />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'æ–‡ç« ',
                PAGES: 'é¡µé¢',
                CATEGORIES: 'åˆ†ç±»',
                TAGS: 'æ ‡ç­¾',
                UNTITLED: '(æ— æ ‡é¢˜)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>

<script src="/js/insight.js"></script>

    
</body>
</html>